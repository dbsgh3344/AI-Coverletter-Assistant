{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"label1 text generation.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1Zi4_qSG4ErwETCQ5cP7azOQ_y3VQ5RwR","authorship_tag":"ABX9TyOKG8ms7j9hmxkMl6r5S18s"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"6laqRjN3iZV3","colab_type":"code","outputId":"8aea85b3-d8d4-4845-919e-93fcf74c97e6","executionInfo":{"status":"ok","timestamp":1590407801996,"user_tz":-540,"elapsed":3664,"user":{"displayName":"Mike Pk","photoUrl":"","userId":"01708764291721906768"}},"colab":{"base_uri":"https://localhost:8080/","height":323}},"source":["! nvidia-smi"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Mon May 25 11:56:40 2020       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 440.82       Driver Version: 418.67       CUDA Version: 10.1     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|===============================+======================+======================|\n","|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   34C    P0    26W / 250W |      0MiB / 16280MiB |      0%      Default |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                       GPU Memory |\n","|  GPU       PID   Type   Process name                             Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"X8iRpghy6GmT","colab_type":"code","colab":{}},"source":["import os\n","import pandas as pd\n","import numpy as np\n","os.chdir('/content/drive/My Drive/tabditor/FromZero/rsc')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"LYeGRtZo7Mdl","colab_type":"text"},"source":["# 데이터 준비"]},{"cell_type":"markdown","metadata":{"id":"Rby75tNNf9CF","colab_type":"text"},"source":["## label 1에 해당하는 데이터 불러오기"]},{"cell_type":"code","metadata":{"id":"wRIE68jY6oFc","colab_type":"code","outputId":"4c49f299-942a-4d53-94cf-4e2abd57f861","executionInfo":{"status":"ok","timestamp":1591610870838,"user_tz":-540,"elapsed":1585,"user":{"displayName":"Mike Pk","photoUrl":"","userId":"01708764291721906768"}},"colab":{"base_uri":"https://localhost:8080/","height":460}},"source":["label = pd.read_csv('label_1.csv')\n","print(label.shape)\n","label.head()"],"execution_count":2,"outputs":[{"output_type":"stream","text":["(5541, 7)\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>index</th>\n","      <th>qus</th>\n","      <th>ans</th>\n","      <th>prep_qus</th>\n","      <th>label</th>\n","      <th>prepro_label</th>\n","      <th>prepro_ans</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>9269</td>\n","      <td>[Olive Young과 함께 마음까지 All live young하는 삶을 꿈꾸다]</td>\n","      <td>\\n제가 올리브영에 입사하고 싶은 이유는 올리브영만의 기업철학이 제가 지향하는 삶의...</td>\n","      <td>OliveYoung과함께마음까지Allliveyoung하는삶을꿈꾸다</td>\n","      <td>[1]</td>\n","      <td>1</td>\n","      <td>제가 올리브영에 입사하고 싶은 이유는 올리브영만의 기업철학이 제가 지향하는 삶의 방...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>17155</td>\n","      <td>경쟁과 협력 가운데 더 중요하다고 생각하는 것</td>\n","      <td>\\r\\n무한경쟁시대일수록 역설적으로 협력의 힘이 더욱 중요하다고 생각합니다. 함께 ...</td>\n","      <td>경쟁과협력가운데더중요하다고생각하는것</td>\n","      <td>[1]</td>\n","      <td>1</td>\n","      <td>무한경쟁시대일수록 역설적으로 협력의 힘이 더욱 중요하다고 생각합니다 함께 힘을 합친...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>9623</td>\n","      <td>[고퀄리티 제품과 서비스를 갖춘 GS엠비즈의 고퀄리티 영업관리자가 되겠습니다]</td>\n","      <td>\\r\\nGS엠비즈는 \"The Best Company for Customers\"를 비...</td>\n","      <td>고퀄리티제품과서비스를갖춘GS엠비즈의고퀄리티영업관리자가되겠습니다</td>\n","      <td>[1]</td>\n","      <td>1</td>\n","      <td>GS엠비즈는 The Best Company for Customers를 비전으로 자동...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4410</td>\n","      <td>공공기관으로서 사업 추진에 필요한 영화계 의견수렴 방법을 제시하여 주십시오 1000바이트</td>\n","      <td>\\r\\n\"현장 상황을 존중하는 적극적인 자세와 직접 소통의 중요성\"\\r 저는 영화진...</td>\n","      <td>공공기관으로서사업추진에필요한영화계의견수렴방법을제시하여주십시오1000바이트</td>\n","      <td>[1,2]</td>\n","      <td>1,2</td>\n","      <td>현장 상황을 존중하는 적극적인 자세와 직접 소통의 중요성 저는 영화진흥위원회의 의견...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>7456</td>\n","      <td>공공기관으로써 갖추어야 할 덕목</td>\n","      <td>\\r\\n한국토지공사는 사기업과는 다른 공기업이기 때문에 개인보다는 국민을 먼저 생각...</td>\n","      <td>공공기관으로써갖추어야할덕목</td>\n","      <td>[1]</td>\n","      <td>1</td>\n","      <td>한국토지공사는 사기업과는 다른 공기업이기 때문에 개인보다는 국민을 먼저 생각하는 배...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   index  ...                                         prepro_ans\n","0   9269  ...  제가 올리브영에 입사하고 싶은 이유는 올리브영만의 기업철학이 제가 지향하는 삶의 방...\n","1  17155  ...  무한경쟁시대일수록 역설적으로 협력의 힘이 더욱 중요하다고 생각합니다 함께 힘을 합친...\n","2   9623  ...  GS엠비즈는 The Best Company for Customers를 비전으로 자동...\n","3   4410  ...  현장 상황을 존중하는 적극적인 자세와 직접 소통의 중요성 저는 영화진흥위원회의 의견...\n","4   7456  ...  한국토지공사는 사기업과는 다른 공기업이기 때문에 개인보다는 국민을 먼저 생각하는 배...\n","\n","[5 rows x 7 columns]"]},"metadata":{"tags":[]},"execution_count":2}]},{"cell_type":"markdown","metadata":{"id":"E1BdWNPw6xqU","colab_type":"text"},"source":["# text preprocessing"]},{"cell_type":"markdown","metadata":{"id":"jI3o7zFwgDXy","colab_type":"text"},"source":["## train을 위한 answer 데이터 전처리"]},{"cell_type":"code","metadata":{"id":"ex24jrju7RWe","colab_type":"code","outputId":"50556805-3876-4472-bf6b-110308dc214e","executionInfo":{"status":"ok","timestamp":1591610704795,"user_tz":-540,"elapsed":2905,"user":{"displayName":"Mike Pk","photoUrl":"","userId":"01708764291721906768"}},"colab":{"base_uri":"https://localhost:8080/","height":233}},"source":["label.prepro_ans"],"execution_count":3,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0       제가 올리브영에 입사하고 싶은 이유는 올리브영만의 기업철학이 제가 지향하는 삶의 방...\n","1       무한경쟁시대일수록 역설적으로 협력의 힘이 더욱 중요하다고 생각합니다 함께 힘을 합친...\n","2       GS엠비즈는 The Best Company for Customers를 비전으로 자동...\n","3       현장 상황을 존중하는 적극적인 자세와 직접 소통의 중요성 저는 영화진흥위원회의 의견...\n","4       한국토지공사는 사기업과는 다른 공기업이기 때문에 개인보다는 국민을 먼저 생각하는 배...\n","                              ...                        \n","5536    식품 연구원으로의 성장저의 지도교수님은 한 분야의 전문가가 되려면 최소 10년의 지...\n","5537    실험을 통한 분석력과 조별과제에서 배운 소통능력 생산 관리 직무는 현장에서 생산 계...\n","5538    저는  태권도 동아리 소속의 아낌없이 가르쳐주고 소통하는 멘토입니다에 입학 후 건강...\n","5539    병원에 입원해 본 사람은 매 시간이 얼마나 감사한지 알 것입니다 사고로 군용 차량과...\n","5540    병원에 입원해 본 사람은 매 시간이 얼마나 감사한지 알 것입니다 사고로 군용 차량과...\n","Name: prepro_ans, Length: 5541, dtype: object"]},"metadata":{"tags":[]},"execution_count":3}]},{"cell_type":"markdown","metadata":{"id":"eRT8ufrXgRoN","colab_type":"text"},"source":["### keras tokenizer로 어절 단위의 tokenizing을 진행한다.  \n","keras tokenizer 장점\n","- word to index를 진행해준다.\n","- word to sequence를  진행해준다. \n"]},{"cell_type":"code","metadata":{"id":"YUPSeRCgD6Bi","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"outputId":"d3056cbc-14ab-496c-b1c4-399cf7e3478f","executionInfo":{"status":"ok","timestamp":1591610876427,"user_tz":-540,"elapsed":3927,"user":{"displayName":"Mike Pk","photoUrl":"","userId":"01708764291721906768"}}},"source":["from keras.preprocessing.text import Tokenizer\n","\n","token = Tokenizer()\n","token.fit_on_texts(label.prepro_ans)"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"fTNPU65lHQDi","colab_type":"code","outputId":"b3656299-1318-4fb3-b6b3-7b56b96a4d8c","executionInfo":{"status":"ok","timestamp":1591610876431,"user_tz":-540,"elapsed":2101,"user":{"displayName":"Mike Pk","photoUrl":"","userId":"01708764291721906768"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["# 어절단위 tokenizing 진행 후, 단어의 개수 124385개  \n","len(token.word_index)"],"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/plain":["124385"]},"metadata":{"tags":[]},"execution_count":4}]},{"cell_type":"code","metadata":{"id":"j-unqkvlHZB0","colab_type":"code","colab":{}},"source":["slide_data = []\n","\n","for i in label.prepro_ans:\n","    seq_data = token.texts_to_sequences([i])\n","    for j in range(1,len(seq_data[0])):\n","        tmp = seq_data[0][0:j+1]\n","        slide_data.append(tmp)\n","\n","        "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"d_l3lMmqIHdV","colab_type":"code","outputId":"d145aaef-a9b3-4676-f82f-e1800fac390c","executionInfo":{"status":"ok","timestamp":1591610719140,"user_tz":-540,"elapsed":746,"user":{"displayName":"Mike Pk","photoUrl":"","userId":"01708764291721906768"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["len(slide_data)"],"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["785537"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"code","metadata":{"id":"lL-OKfOJeel2","colab_type":"code","outputId":"39764565-6e69-4de9-e33b-26dd6a9563be","executionInfo":{"status":"ok","timestamp":1591610881107,"user_tz":-540,"elapsed":3582,"user":{"displayName":"Mike Pk","photoUrl":"","userId":"01708764291721906768"}},"colab":{"base_uri":"https://localhost:8080/","height":197}},"source":["slide_data[:10]"],"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[[20, 24506],\n"," [20, 24506, 6076],\n"," [20, 24506, 6076, 201],\n"," [20, 24506, 6076, 201, 341],\n"," [20, 24506, 6076, 201, 341, 51179],\n"," [20, 24506, 6076, 201, 341, 51179, 51180],\n"," [20, 24506, 6076, 201, 341, 51179, 51180, 20],\n"," [20, 24506, 6076, 201, 341, 51179, 51180, 20, 4205],\n"," [20, 24506, 6076, 201, 341, 51179, 51180, 20, 4205, 450],\n"," [20, 24506, 6076, 201, 341, 51179, 51180, 20, 4205, 450, 9291]]"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"code","metadata":{"id":"J8Zo_KdsO2Zq","colab_type":"code","outputId":"be3eaebd-4f9a-428f-8124-fb181c98ba30","executionInfo":{"status":"ok","timestamp":1591610881111,"user_tz":-540,"elapsed":1281,"user":{"displayName":"Mike Pk","photoUrl":"","userId":"01708764291721906768"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["maxlen = max([len(i) for i in slide_data])\n","maxlen"],"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["975"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"code","metadata":{"id":"7qPIAUeEIqkZ","colab_type":"code","outputId":"3ea28044-e510-44af-bedb-6719c557dbdb","executionInfo":{"status":"ok","timestamp":1591610899234,"user_tz":-540,"elapsed":10350,"user":{"displayName":"Mike Pk","photoUrl":"","userId":"01708764291721906768"}},"colab":{"base_uri":"https://localhost:8080/","height":143}},"source":["from keras.preprocessing.sequence import pad_sequences\n","\n","seq_data = pad_sequences(slide_data,maxlen=maxlen)\n","seq_data"],"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[    0,     0,     0, ...,     0,    20, 24506],\n","       [    0,     0,     0, ...,    20, 24506,  6076],\n","       [    0,     0,     0, ..., 24506,  6076,   201],\n","       ...,\n","       [    0,     0,     0, ..., 13138,  1143,   450],\n","       [    0,     0,     0, ...,  1143,   450,   249],\n","       [    0,     0,     0, ...,   450,   249,   284]], dtype=int32)"]},"metadata":{"tags":[]},"execution_count":8}]},{"cell_type":"code","metadata":{"id":"VtP8q-6re5nh","colab_type":"code","colab":{}},"source":["x_train = seq_data[:,:-1]\n","y_train = seq_data[:,-1]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"u01HiLptZYXe","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"outputId":"73d33839-90b4-47ba-efec-cb4a133c0d1b","executionInfo":{"status":"ok","timestamp":1591610927261,"user_tz":-540,"elapsed":703,"user":{"displayName":"Mike Pk","photoUrl":"","userId":"01708764291721906768"}}},"source":["max_y = max([i for i in y_train])\n","max_y"],"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/plain":["124385"]},"metadata":{"tags":[]},"execution_count":11}]},{"cell_type":"code","metadata":{"id":"eBKElIwgpXie","colab_type":"code","colab":{}},"source":["# from keras.utils import to_categorical\n","# y_train = to_categorical(y_train, num_classes=max_y+1)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fPESpGYyZkuB","colab_type":"text"},"source":["# LSTM 적용"]},{"cell_type":"code","metadata":{"id":"ZYqllPA1ZUsl","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":468},"outputId":"644cff00-8de8-4df1-f704-1786861f4608","executionInfo":{"status":"error","timestamp":1591611662765,"user_tz":-540,"elapsed":678415,"user":{"displayName":"Mike Pk","photoUrl":"","userId":"01708764291721906768"}}},"source":["from keras.layers import Dense,Embedding,LSTM\n","from keras.models import Sequential\n","from keras.models import load_model\n","\n","\n","model = Sequential()\n","model.add(Embedding(max_y+1,10,input_length=maxlen-1))\n","model.add(LSTM(64))\n","model.add(Dense(max_y+1,activation='softmax'))\n","# model.add(Dense(1,activation='softmax'))\n","\n","model.compile(loss='sparse_categorical_crossentropy',optimizer = 'adam',metrics=['accuracy']) #metrics = 평가척도\n","\n","# model.load_weights('ckpt_epoch200.h5')\n","model.fit(x_train,y_train,epochs = 100,verbose=2)\n","\n","# model.save('ckpt_epoch100.h5')"],"execution_count":15,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n","  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1/100\n"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-15-729694dc7df5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# model.load_weights('ckpt_epoch200.h5')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# model.save('ckpt_epoch100.h5')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1239\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1241\u001b[0m     def evaluate(self,\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    194\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3790\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3791\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3792\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3793\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3794\u001b[0m     \u001b[0;31m# EagerTensor.numpy() will often make a copy to ensure memory safety.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1603\u001b[0m       \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mFor\u001b[0m \u001b[0minvalid\u001b[0m \u001b[0mpositional\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mkeyword\u001b[0m \u001b[0margument\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1604\u001b[0m     \"\"\"\n\u001b[0;32m-> 1605\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1607\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1643\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[1;32m   1644\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[0;32m-> 1645\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1646\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1647\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1745\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1746\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1748\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    596\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    599\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m           outputs = execute.execute_with_cancellation(\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]}]}